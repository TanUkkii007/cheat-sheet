{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational auto-encoder\n",
    "\n",
    "\n",
    "\n",
    "Tutorial on Variational Autoencoders https://arxiv.org/abs/1606.05908\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition and notation\n",
    "\n",
    "\n",
    "$X$: datapoints in possibly high-dimensional space $\\mathcal{X}$\n",
    "\n",
    "$P(X)$: a generative model of distribution defined over datapoints X\n",
    "\n",
    "$z$: latent variable in high dimensional space $\\mathcal{Z}$\n",
    "\n",
    "$f(z, \\theta)$: deterministic function parameterized by $\\theta$ where $f: \\mathcal{Z} \\times \\mathcal{\\Theta} \\to \\mathcal{X}$\n",
    "\n",
    "$\\mathcal{D}[P(x)\\|Q(x)] = -\\int P(x)\\ln \\frac{Q(x)}{P(x)}dx = -\\mathbb{E}_{x \\sim P}[\\log \\frac{Q(x)}{P(x)}]$: KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "Maximize the following equation by optimizting $\\theta$.\n",
    "\n",
    "$P(X) = \\int P(X|z;\\theta)P(z)dz$\n",
    "\n",
    "Normally,\n",
    "\n",
    "$P(X|z;\\theta) = \\mathcal{N}(X|f(z, \\theta), \\sigma^2 * I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation between $P(X)$ and $\\mathbb{E}_{z \\sim Q}[\\log P(X|z)]$\n",
    "\n",
    "$\\log P(X) - \\mathcal{D}[Q(z)\\|P(z|X)] = \\mathbb{E}_{z \\sim Q}[\\log P(X|z)] - \\mathcal{D}[Q(z)\\|P(z)]$\n",
    "\n",
    "If we change $Q(z)$ to $Q(z|X)$,\n",
    "\n",
    "$\\log P(X) - \\mathcal{D}[Q(z|X)\\|P(z|X)] = \\mathbb{E}_{z \\sim Q}[\\log P(X|z)] - \\mathcal{D}[Q(z|X)\\|P(z)]$ ... (5)\n",
    "\n",
    "We want to maximize $\\log P(X)$ while simultaneously minimizing $\\mathcal{D}[Q(z|X)\\|P(z|X)]$.\n",
    "\n",
    "Instead we can optimize the right hand side via stochastic gradient descent given the right choice of Q.\n",
    "\n",
    "---\n",
    "\n",
    "$\\mathcal{D}[Q(z)\\|P(z|X)] = \\mathbb{E}_{z \\sim Q}[\\log Q(z) - \\log P(z|X)]$\n",
    "\n",
    "$ = \\mathbb{E}_{z \\sim Q}[\\log Q(z) - \\log P(X|z) - \\log P(z)] + \\log P(X)$  (by applying Bayes rule.)\n",
    "\n",
    "$\\log P(X) - \\mathcal{D}[Q(z)\\|P(z|X)] = -\\mathbb{E}_{z \\sim Q}[\\log Q(z) - \\log P(X|z) - \\log P(z)]$\n",
    "\n",
    "$ = \\mathbb{E}_{z \\sim Q}[\\log P(X|z)] + \\mathbb{E}_{z \\sim Q}[\\log P(z) - \\log Q(z)]$\n",
    "\n",
    "$ = \\mathbb{E}_{z \\sim Q}[\\log P(X|z)] - \\mathcal{D}[Q(z)\\|P(z)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the objective (1): KL divergence of two Gaussians\n",
    "\n",
    "\n",
    "We optimize the right hand side of (5). \n",
    "\n",
    "$\\mathbb{E}_{z \\sim Q}[\\log P(X|z)] - \\mathcal{D}[Q(z|X)\\|P(z)]$\n",
    "\n",
    "First we compute the second term $\\mathcal{D}[Q(z|X)\\|P(z)]$.\n",
    "\n",
    "Let\n",
    "\n",
    "$P(z) = \\mathcal{N}(z|0, I)$\n",
    "\n",
    "$Q(z|X) = \\mathcal{N}(z|\\mu(X;\\theta), \\Sigma(X;\\theta))$\n",
    "\n",
    "Then \n",
    "\n",
    "$\\mathcal{D}[Q(z|X)\\|P(z)] = \\mathcal{D}[\\mathcal{N}\\left(z|\\mu(X), \\Sigma(X)\\right) \\| \\mathcal{N}(0, I)]$\n",
    "\n",
    "$ = \\frac{1}{2}\\left\\{ \\mathrm{tr}\\left(\\Sigma(X)\\right) + \\left(- \\mu(X)\\right)^\\top(- \\mu(X)) - k + \\log\\left(\\frac{1}{\\det\\Sigma(X)}\\right) \\right\\}$\n",
    "\n",
    "$ = \\frac{1}{2}\\left\\{ \\mathrm{tr}\\left(\\Sigma(X)\\right) + \\mu(X)^\\top\\mu(X) - k - \\log\\det\\left(\\Sigma(X)\\right) \\right\\}$\n",
    "\n",
    "Since \n",
    "\n",
    "$\\mathcal{D}[\\mathcal{N}(\\mu_1, \\Sigma_1)\\|\\mathcal{N}(\\mu_2, \\Sigma_2)] =\n",
    "\\frac{1}{2}\\left\\{ \\mathrm{tr}\\left(\\Sigma_2^{-1}\\Sigma_1\\right) + \\left(\\mu_2 - \\mu_1\\right)^\\top \\Sigma_2^{-1}(\\mu_2 - \\mu_1) - k + \\log\\left(\\frac{\\det \\Sigma_2}{\\det\\Sigma_1}\\right) \\right\\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the objective (2): Reparametrization trick\n",
    "\n",
    "We want to compute the first term by sampling.\n",
    "\n",
    "$\\mathbb{E}_{z \\sim Q}[\\log P(X|z)]$\n",
    "\n",
    "In this equation, parameters from Q such as $\\mu(X)$ and $\\Sigma(X)$ dissapears. This prvents backpropagation.\n",
    "\n",
    "Let\n",
    "\n",
    "$\\epsilon \\sim \\mathcal{N}(0, I)$\n",
    "\n",
    "Then\n",
    "\n",
    "$z = \\mu(X) + \\Sigma^{1/2}(X) * \\epsilon$\n",
    "\n",
    "$\\mathbb{E}_{z \\sim Q}[\\log P(X|z)] = \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0,I)}[\\log P(X|z=\\mu(X) + \\Sigma^{1/2}(X) * \\epsilon)]$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
